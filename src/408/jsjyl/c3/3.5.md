---
title: 3.5 高速缓冲处理器 Cache
---

```markmap
---
markmap:
  colorFreezeLevel: 3
---
# 高速缓冲处理器 Cache

## 1. 基本原理

- Cache层：缓和主存和CPU之间的速度矛盾
- Cache被集成在CPU内部
- Cache用SRAM实现，速度快，成本高
- CPU与Cache和主存间信息交互的单位是字，Cache与主存间信息交互的单位是块

### 1.1 局部性原理

- **空间局部性**：在最近的未来要用到的信息，很可能与现在正在使用的信息在存储空间上是邻近的
  - 数字元素、顺序执行的指令代码
  - 指令Cache通常比数据Cache具有更好的空间局部性
- **时间局部性**：在最近的未来要用到的信息，很可能是现在正在使用的信息
  - 循环结构的指令代码，现在正在用的信息很可能马上会被再用一次

### 1.2 性能分析

- $t_c$：CPU在Cache中查找数据的时间
- $t_m$：CPU在主存中查找数据的时间
- 命中率 H：CPU欲访问的信息已在Cache中的比率
- 缺失率(未命中率)：M=1-H
- Cache——主存系统的平均访问时间t为
  - $$t=H·t_c+(1-H)(t_c+t_m)$$
  - 或：$$t=H·t_c+(1-H)(t_m)$$

## 2. Cache和主存的映射方式

- 目的：区分Cache中块号和主存块号之间的关系

### 2.1 全相联映射

- 主存块可以放在Cache中的任意位置
- Cache每行有标记，用于指出该行来自主存的哪一块
- 优点：冲突概率低，利用率高，命中率高
- 缺点：比较速度较慢，实现成本较高

### 2.2 直接映射

- 每个主存块只能放到一个特定的位置
- Cache块号=主存块号%Cache总块数
- 优点：对于任意一个地址，只需对比一个标记，速度最快
- 缺点：冲突概率最高，空间利用率最低

### 2.3 组相联映射

- Cache块分为若干组，每个主存块可放到特定分组中的任意一个位置
- 优点：权衡了全相联映射和直接映射的优缺点

### 2.4 比较器

- 比较器位数等于Tag标记字段的位数
- **直接映射**：只需一个比较器
- **全相联映射**：n行Cache需要n个比较器
- **组相联映射**：r路组相联映射需要r个比较器

## 3. 替换策略

### 3.1 随机算法

- 随机选择一个Cache块进行替换

### 3.2 先进先出算法(FIFO)

- 按照Cache块调入的顺序进行替换

### 3.3 最近最少使用算法(LRU)

- 替换最近最少使用的Cache块

### 3.4 最不经常使用算法(LFU)

- 替换访问次数最少的Cache块

## 4. Cache写策略

### 4.1 写命中——全写法

- 数据同时写入Cache和主存
- 使用写缓冲优化

### 4.2 写命中——回写法

- 只修改Cache，块被换出时才写回主存
- 需要设置脏位

### 4.3 写不命中——写分配法

- 将主存中的块调入Cache后再修改

### 4.4 写不命中——非写分配法

- 只写入主存，不调入Cache

### 4.5 多级Cache

- 离CPU越近的速度越快，容量越小
- 离CPU越远的速度越慢，容量越大
```

## 1. 基本原理

Cache层：缓和主存和CPU之间的速度矛盾

实际上，Cache被集成在CPU内部

Cache用SRAM实现，速度快，成本高

CPU与Cache和主存间信息交互的单位是字，而Cache与主存间信息交互的单位是块

:::tip
一般来说，Cache的块(行)和主存的块大小是一致的
:::

### 1.1 局部性原理



**空间局部性**：在最近的未来要用到的信息，很可能与现在正在使用的信息在存储空间上是邻近的

例如数字元素、顺序执行的指令代码

故指令Cache通常比数据Cache具有更好的空间局部性

**时间局部性**：在最近的未来要用到的信息，很可能是现在正在使用的信息

例如循环结构的指令代码，现在正在用的信息很可能马上会被再用一次

可以把CPU目前访问的地址“周围”的部分数据放到Cache中

### 1.2 性能分析
$t_c$：CPU在Cache中查找数据的时间

$t_m$：CPU在主存中查找数据的时间

命中率 H：CPU欲访问的信息已在Cache中的比率

缺失率(未命中率)：M=1-H

Cache——主存系统的平均访问时间t为

$$t=H·t_c+(1-H)(t_c+t_m)$$

CPU会先访问Cache，若未命中再访问主存

或：

$$t=H·t_c+(1-H)(t_m)$$

即，同时访问Cache和主存


将主存的存储空间分块，主存与Cache之间以块为单位进行数据交换

:::tip
操作系统中，一个块也称为一个页/页面/页框

Cache中的块也称为行
:::

每次被访问的主存块，一定会被立即调入Cache

:::tip 主存块大小和Cache的关系

主存块过大，会导致Cache的行数变少，即存放主存块的位置变少，导致降低命中率

主存块过小，不能很好地利用空间局部性，导致缺失率变高，降低命中率

:::

:::danger
当Cache中有空闲行且匹配失败时，不管有没有替换，仍然算作一次缺失(未命中)
:::

## 2. Cache和主存的映射方式

目的：区分Cache中块号和主存块号之间的关系

全相联映射：主存块可以放在Cache中的任意位置

直接映射：每个主存块只能放到一个特定的位置

Cache块号=主存块号%Cache总块数

组相联映射：Cache块分为若干组，每个主存块可放到特定分组中的任意一个位置

组号：主存块号%分组数

:::tip
注意逻辑地址和物理地址之间的区分

当谈及物理空间的块和逻辑空间的页以及它们之间的相互转换时，通常假设块的大小和页的大小一致，以方便解决问题
:::

:::tip
为了说明Cache行中的信息是否有效，每个Cache行需要一个有效位
:::
###  2.1 全相联映射

随便放

Cache每行会有标记，用于指出该行来自主存的哪一块

因此CPU访存时需要与所有Cache行的标记进行比较

优点：冲突概率低，利用率高，命中率高

缺点：比较速度较慢，实现成本较高

:::tip 全相连映射的地址结构
当CPU获得了一个**主存地址**后，它会将该主存地址分为两部分进行解析，如下表格：

| Tag位(高位) | 块内地址(低位) |
| --- | --- |
| 剩下的都是Tag位，用于标识主存中的块 | 若主存块大小为$2^nB$，则块内地址(偏移量)的位数为n位 |
:::

### 2.2 直接映射

只能放在固定位置

位置=主存块号%Cache总块数


优点：对于任意一个地址，只需对比一个标记，速度最快

缺点：冲突概率最高，空间利用率最低

从映射函数可以看出，若Cache共有$2^n$行，则主存块号的低c位正好是它要装入的Cache行号，将高位地址设置为标记

CPU访存过程：首先根据低c位找到对应的Cache行，将高位地址和标记进行比较，若相等且有效位为1，则命中成功

:::tip 直接映射的地址结构
当CPU获得了一个**主存地址**后，它会将该主存地址分为三部分进行解析，如下表格：

| 标记(高位) | Cache行号 | 块内地址(低位) |
| --- | --- | --- |
| 标记位数即主存容量(块数)/Cache容量(块数) | 去除高位标记和低位地址后，剩下的就是Cache行号，用来标识数据存在了Cache中第几行 | 通常又称偏移量<br>假设Cache内每个字块有$2^nB$，则块内地址一共$n$位 |
:::

### 2.3 组相联映射

可放到特定分组

分组数=总容量/(字块大小×组内地址数量)

所属分组=主存块号%分组数

若分组共有$2^n$个，则地址低n位即为分组号

假设每组有r个地址，则称为r-路组相联映射

:::tip 组相连映射的地址结构
当CPU获得了一个**主存地址**后，它会将该主存地址分为三部分进行解析，如下表格：

| 标记(高位) | Cache组号 | 块内地址(低位) |
| --- | --- | --- |
| 标记位数即主存容量(块数)/Cache组数 | 去除高位标记和低位地址后，剩下的就是Cache组号，用来标识数据存在了第几组<br>换句话说，若有$2^n$组，则Cache组号就有n位 | 通常又称偏移量<br>假设Cache内每个字块有$2^nB$，则块内地址一共$n$位 |
:::

### 2.4 比较器

==比较器位数等于Tag标记字段的位数==

直接映射：由于每块只能映射到唯一的Cache行，因此==只需设置1个比较器==

全相联映射：全相联映射下，每一个Cache行都需要配备一个比较器，用来将本行的标签与待访问的地址标签位进行比对。所有比较器并行工作，也就是说==Cache有几行，就要几个比较器==

组相联映射：r路组相联映射==需要设置r个比较器==，用于在对应分组中与r个Cache行进行比较

## 3. Cache中主存块的替换算法

==直接映射无需考虑替换算法==

### 3.1 随机算法(RAND)

若Cache已满，随机选择一块进行替换

实现简单，但完全没考虑局部性原理。

命中率低，实际效果不稳定

### 3.2 先进先出算法(FIFO)

若Cache已满，则替换最先被调入Cache的块

实现简单，但仍然没考虑局部性原理

### 3.3 ==近期最少使用算法(LRU)==

Least Recently Used

当Cache行冲突时，选择最久没被使用过的Cache行进行替换

为每个Cache块设置一个计数器，用于记录每个Cache块已经有多久没被访问了。当Cache满后，替换计数器最大的块

命中时，所在行计数器清零，计数器的值比其低的+1

未命中但是有空闲行时，新装入的计数器置零，其余计数器+1

未命中且无空闲行时，计数器最大的行的信息快被淘汰

LRU基于局部性原理：近期被访问过的主存块，在不久的将来也很有可能会被再次访问

LRU算法的实际运行效果优秀，Cache命中率高

若被频繁访问的主存块数量>Cache行的数量，则有可能发生“抖动”

:::tip
替换控制位的位数取决于Cache有多少行(组)

假设有$n$行(组)，则替换控制位一共有$\log_2n$位
:::

### 3.4 最不经常使用算法(LFU)

Least Frequently Used

为每一个Cache块设置一个计数器，用于记录每个Cache块被访问过几次，当Cache满后替换计数器最小的

新调入的块计数器=0，之后每被访问一次计数器+1.

若有多个计数器最小的行，则可以按照行号递增，或按FIFO策略

曾经被经常访问的主存块在未来不一定会用到

因此并没有很好地遵循局部性原理，实际运行效果不如LRU

## 4. Cache写策略

CPU修改了Cache中的数据副本，如何确保主存中数据母本的一致性？

读操作不会导致Cache与主存数据不一致

### 4.1 写命中——全写法

当CPU对Cache写命中时，必须把数据同时写入Cache和主存，一般使用写缓冲来优化

访存次数增加，速度变慢，但更能保证数据一致性

写缓冲：SRAM实现的FIFO队列

使用写缓冲，若写报错不频繁，则效果很好；若写缓冲频繁，则可能会因为写缓冲饱和而发生阻塞

### 4.2 写命中——回写法

当CPU对Cache写命中时，只修改Cache的内容，而不立即写入主存。

只有当此块被换出时才写回主存

需要给Cache设置一个脏位——表示Cache行是否被修改过

减少了访存次数，但存在数据不一致的隐患

### 4.3 写不命中——写分配法

写不命中：要写的时候发现Cache没有

当CPU对Cache写不命中时，把主存中的块调入Cache，在Cache中修改，通常搭配写回法使用

### 4.4 写不命中——非写分配法

写不命中时，只写入主存，不调入Cache

通常搭配全写法使用

### 4.5 多级Cache

离CPU越近的速度越快，容量越小

离CPU越远的速度越慢，容量越大

各级Cache间通常采用全写法+非写分配法

Cache和主存间常采用写回法+写分配法

## 5. 总结

### 1. Cache每行的信息

==和计算Cache的总位数有关==

| 名字 | 位数 | 功能 |
| --- | ---- | ---- |
| 有效位 | 1位 | 用于标识该Cache行是否包含有效数据 |
| Tag位 | 主存块数/Cache行数 | 用于标识Cache行中数据对应的主存位置 |
| 数据位 | 取决于系统设计 | 该行存储的数据内容，通常是几字节到几百字节 |
| 脏位 | 1位 | 用于回写法，标记该行是否被修改过 |
| 替换控制位 | 只有LRU会用 | 用于记录该行的使用历史，以实现LRU替换策略 |

总结：有效位、Tag位、数据位必有

如果用了回写法，则要加1位脏位

如果用了LRU算法，则要加若干位替换控制位

Cache有多少行(组)，就要有$\log_2n$位替换控制位

### 2. 解析主存地址

CPU得到了主存地址后，首先会根据映射方式来解析主存地址

对于==直接映射==：

| 标记(高位) | Cache行号 | 块内地址(低位) |
| --- | --- | --- |
| 标记位数即主存容量(块数)/Cache容量(块数) | 去除高位标记和低位地址后，剩下的就是Cache行号，用来标识数据存在了Cache中第几行 | 通常又称偏移量<br>假设Cache内每个字块有$2^nB$，则块内地址一共$n$位 |

对于==全相联映射==：

| Tag位(高位) | 块内地址(低位) |
| --- | --- |
| 剩下的都是Tag位，用于标识主存中的块 | 若主存块大小为$2^nB$，则块内地址(偏移量)的位数为n位 |

对于==组相联映射==：

| 标记(高位) | Cache组号 | 块内地址(低位) |
| --- | --- | --- |
| 标记位数即主存容量(块数)/Cache组数 | 去除高位标记和低位地址后，剩下的就是Cache组号，用来标识数据存在了第几组<br>换句话说，若有$2^n$组，则Cache组号就有n位 | 通常又称偏移量<br>假设Cache内每个字块有$2^nB$，则块内地址一共$n$位 |
































