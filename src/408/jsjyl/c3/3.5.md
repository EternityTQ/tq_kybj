---
title: 3.5 高速缓冲处理器 Cache
---

## 1. 基本原理

Cache层：缓和主存和CPU之间的速度矛盾

实际上，Cache被集成在CPU内部

Cache用SRAM实现，速度快，成本高
### 1. 局部性原理



空间局部性：在最近的未来要用到的信息，很可能与现在正在使用的信息在存储空间上是邻近的(例如数字元素、顺序执行的指令代码)

时间局部性：在最近的未来要用到的信息，很可能是现在正在使用的信息(例如循环结构的指令代码，现在正在用的信息很可能马上会被再用一次)

可以把CPU目前访问的地址“周围”的部分数据放到Cache中

### 2. 性能分析
$t_c$：CPU在Cache中查找数据的时间

$t_m$：CPU在主存中查找数据的时间

命中率 H：CPU欲访问的信息已在Cache中的比率

缺失率(未命中率)：M=1-H

Cache——主存系统的平均访问时间t为

$$t=H·t_c+(1-H)(t_c+t_m)$$

CPU会先访问Cache，若未命中再访问主存

或：

$$t=H·t_c+(1-H)(t_m)$$

即，同时访问Cache和主存


将主存的存储空间分块，主存与Cache之间以块为单位进行数据交换

:::tip
操作系统中，一个块也称为一个页/页面/页框

Cache中的块也称为行
:::

每次被访问的主存块，一定会被立即调入Cache

## 2. Cache和主存的映射方式

目的：区分Cache中块号和主存块号之间的关系

全相联映射：主存块可以放在Cache中的任意位置

直接映射：每个主存块只能放到一个特定的位置

Cache块号=主存块号%Cache总块数

组相联映射：Cache块分为若干组，每个主存块可放到特定分组中的任意一个位置

组号：主存块号%分组数

###  2.1 全相联映射

随便放

Cache每行会有标记，用于指出该行来自主存的哪一块

因此CPU访存时需要与所有Cache行的标记进行比较

优点：冲突概率低，利用率高，命中率高

缺点：比较速度较慢，实现成本较高

### 2.2 直接映射

只能放在固定位置

位置=主存块号%Cache总块数


优点：对于任意一个地址，只需对比一个标记，速度最快

缺点：冲突概率最高，空间利用率最低

从映射函数可以看出，若Cache共有$2^n$行，则主存块号的低c位正好是它要装入的Cache行号，将高位地址设置为标记

CPU访存过程：首先根据低c位找到对应的Cache行，将高位地址和标记进行比较，若相等且有效位为1，则命中成功

### 2.3 组相联映射

可放到特定分组

所属分组=主存块号%分组数

若分组共有$2^n$个，则地址低n位即为分组号

## 3. Cache中主存块的替换算法

直接映射无需考虑替换算法

### 1. 随机算法(RAND)

若Cache已满，随机选择一块进行替换

实现简单，但完全没考虑局部性原理。

命中率低，实际效果不稳定

### 2. 先进先出算法(FIFO)

若Cache已满，则替换最先被调入Cache的块

实现简单，但仍然没考虑局部性原理

### 3. ==近期最少使用算法(LRU)==

Least Recently Used

当Cache行冲突时，选择最久没被使用过的Cache行进行替换

为每个Cache块设置一个计数器，用于记录每个Cache块已经有多久没被访问了。当Cache满后，替换计数器最大的块

命中时，所在行计数器清零，计数器的值比其低的+1

未命中但是有空闲行时，新装入的计数器置零，其余计数器+1

未命中且无空闲行时，计数器最大的行的信息快被淘汰

LRU基于局部性原理：近期被访问过的主存块，在不久的将来也很有可能会被再次访问

LRU算法的实际运行效果优秀，Cache命中率高

若被频繁访问的主存块数量>Cache行的数量，则有可能发生“抖动”

### 4. 最不经常使用算法(LFU)

Least Frequently Used

为每一个Cache块设置一个计数器，用于记录每个Cache块被访问过几次，当Cache满后替换计数器最小的

新调入的块计数器=0，之后每被访问一次计数器+1.

若有多个计数器最小的行，则可以按照行号递增，或按FIFO策略

曾经被经常访问的主存块在未来不一定会用到

因此并没有很好地遵循局部性原理，实际运行效果不如LRU

## 4. Cache写策略

CPU修改了Cache中的数据副本，如何确保主存中数据母本的一致性？

读操作不会导致Cache与主存数据不一致

### 1. 写命中——全写法

当CPU对Cache写命中时，必须把数据同时写入Cache和主存，一般使用写缓冲来优化

访存次数增加，速度变慢，但更能保证数据一致性

写缓冲：SRAM实现的FIFO队列

使用写缓冲，若写报错不频繁，则效果很好；若写缓冲频繁，则可能会因为写缓冲饱和而发生阻塞

### 2. 写命中——回写法

当CPU对Cache写命中时，只修改Cache的内容，而不立即写入主存。

只有当此块被换出时才写回主存

需要给Cache设置一个脏位——表示Cache行是否被修改过

减少了访存次数，但存在数据不一致的隐患

### 3. 写不命中——写分配法

写不命中：要写的时候发现Cache没有

当CPU对Cache写不命中时，把主存中的块调入Cache，在Cache中修改，通常搭配写回法使用

### 4. 写不命中——非写分配法

写不命中时，只写入主存，不调入Cache

通常搭配全写法使用

### 5. 多级Cache

离CPU越近的速度越快，容量越小

离CPU越远的速度越慢，容量越大

各级Cache间通常采用全写法+非写分配法

Cache和主存间常采用写回法+写分配法






































