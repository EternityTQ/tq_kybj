---
title: 3.5 高速缓冲处理器 Cache
---

## 1. 基本原理

Cache层：缓和主存和CPU之间的速度矛盾

实际上，Cache被集成在CPU内部

Cache用SRAM实现，速度快，成本高
### 1. 局部性原理



空间局部性：在最近的未来要用到的信息，很可能与现在正在使用的信息在存储空间上是邻近的(例如数字元素、顺序执行的指令代码)

时间局部性：在最近的未来要用到的信息，很可能是现在正在使用的信息(例如循环结构的指令代码，现在正在用的信息很可能马上会被再用一次)

可以把CPU目前访问的地址“周围”的部分数据放到Cache中

### 2. 性能分析
$t_c$：CPU在Cache中查找数据

$t_m$：CPU在主存中查找数据

命中率 H：CPU欲访问的信息已在Cache中的比率

缺失率(未命中率)：M=1-H

Cache——主存系统的平均访问时间t为

$$t=H·t_c+(1-H)(t_c+t_m)$$

CPU会先访问Cache，若未命中再访问主存

或：

$$t=H·t_c+(1-H)(t_m)$$

即，同时访问Cache和主存


将主存的存储空间分块，主存与Cache之间以块为单位进行数据交换

操作系统中，一个块也称为一个页/页面/页框

Cache中的块也称为行

每次被访问的主存块，一定会被立即调入Cache

## 2. Cache和主存的映射方式

全相联映射：主存块可以放在Cache中的任意位置

直接映射：每个主存块只能放到一个特定的位置

Cache块号=主存块号%Cache总块数

组相联映射：Cache块分为若干组，每个主存块可放到特定分组中的任意一个位置

组号：主存块号%分组数

###  2.1 全相联映射

随便放































































